# Scripts de Test et Benchmark

Ce dossier contient des scripts utilitaires pour tester et benchmarker les modÃ¨les d'IA.

## ğŸ“‹ Scripts disponibles

### 1. Test des IDs de modÃ¨les

**Fichier:** `test-model-ids.ts`
**Commande:** `npm run test:models`

VÃ©rifie que tous les modÃ¨les d'IA configurÃ©s (OpenAI, Anthropic, Gemini, Grok) sont accessibles avec les clÃ©s API en base de donnÃ©es.

**Utilisation:**
```bash
cd landing
npm run test:models
```

**Ce qu'il teste:**
- Connexion Ã  chaque provider
- ValiditÃ© des IDs de modÃ¨les
- Latence basique de rÃ©ponse

**Sortie exemple:**
```
ğŸ“¡ Testing OPENAI...
   gpt-5-mini... âœ… OK (1234ms)
   gpt-4.1-mini... âœ… OK (987ms)
   o4-mini... âœ… OK (1567ms)
   gpt-5... âœ… OK (2345ms)

ğŸ“Š SUMMARY
âœ… OPENAI: 4/4 models working
```

---

### 2. Benchmark OpenAI (nouveau)

**Fichier:** `benchmark-openai.ts`
**Commande:** `npm run benchmark:openai`

Benchmark complet des modÃ¨les OpenAI avec mÃ©triques dÃ©taillÃ©es de performance.

**Utilisation:**
```bash
cd landing
npm run benchmark:openai
```

**MÃ©triques mesurÃ©es:**

| MÃ©trique | Description |
|----------|-------------|
| **TTFB** | Time to First Byte - Latence avant le premier token (ms) |
| **Total Time** | Temps total de gÃ©nÃ©ration (ms) |
| **Tokens/sec** | Vitesse de gÃ©nÃ©ration en tokens par seconde |
| **Vision Support** | Test avec et sans screenshot |

**Tests effectuÃ©s:**
- âœ… Mode Standard (4 modÃ¨les): gpt-5-mini, gpt-4.1-mini, gpt-4o, gpt-4o-mini
- âœ… Mode Smart (3 modÃ¨les): o4-mini, gpt-5, o1-mini
- âœ… Avec texte seul
- âœ… Avec vision (screenshot)

**Sortie exemple:**
```
ğŸ”¬ OpenAI Model Benchmark
================================================================================

ğŸ”‘ Loading API key from database...
âœ… API key loaded

ğŸ“Š Testing STANDARD MODE models...

   Testing gpt-5-mini...
      â€¢ Text only:  âœ… TTFB: 234ms | Total: 1.23s | 45.2 tok/s
      â€¢ With vision: âœ… TTFB: 456ms | Total: 2.34s | 38.7 tok/s

   Testing gpt-4.1-mini...
      â€¢ Text only:  âœ… TTFB: 189ms | Total: 1.01s | 52.3 tok/s
      â€¢ With vision: âœ… TTFB: 401ms | Total: 2.11s | 42.1 tok/s

ğŸ§  Testing SMART MODE models...

   Testing o4-mini...
      â€¢ Text only:  âœ… TTFB: 567ms | Total: 3.45s | 28.4 tok/s
      â€¢ With vision: âœ… TTFB: 789ms | Total: 4.56s | 24.1 tok/s

================================================================================
ğŸ“ˆ BENCHMARK SUMMARY

ğŸ“Š STANDARD MODE:
   4/4 models working

   Fastest (by TTFB):
      gpt-4.1-mini          189ms | 52.3 tok/s
      gpt-5-mini            234ms | 45.2 tok/s
      gpt-4o                298ms | 41.8 tok/s

ğŸ§  SMART MODE:
   3/3 models working

   Fastest (by TTFB):
      o4-mini               567ms | 28.4 tok/s
      gpt-5                 612ms | 25.7 tok/s
      o1-mini               701ms | 22.3 tok/s

ğŸ‘ï¸  VISION SUPPORT:
   âœ… 7 models support vision
      â€¢ gpt-5-mini
      â€¢ gpt-4.1-mini
      â€¢ gpt-4o
      â€¢ gpt-4o-mini
      â€¢ o4-mini
      â€¢ gpt-5
      â€¢ o1-mini

================================================================================
ğŸ¯ Total: 14/14 tests passed
```

---

## ğŸ”§ PrÃ©requis

### Base de donnÃ©es configurÃ©e
Les scripts utilisent les clÃ©s API stockÃ©es dans la base de donnÃ©es Postgres via Prisma.

**VÃ©rifier la configuration:**
```bash
# 1. VÃ©rifier que .env contient DATABASE_URL et ENCRYPTION_KEY
cat .env | grep -E "DATABASE_URL|ENCRYPTION_KEY"

# 2. VÃ©rifier que la base est migrÃ©e
npx prisma migrate status

# 3. VÃ©rifier les clÃ©s API en base
npx prisma studio
# â†’ Ouvrir la table AdminApiKey
```

### Ajouter une clÃ© API via Prisma Studio
```bash
npx prisma studio
```

1. Aller dans la table `AdminApiKey`
2. CrÃ©er un nouvel enregistrement:
   - `provider`: "OPENAI"
   - `encryptedKey`: Votre clÃ© OpenAI (sera automatiquement encryptÃ©e)
   - `isActive`: true

---

## ğŸ“Š InterprÃ©ter les rÃ©sultats

### TTFB (Time to First Byte)
- **< 200ms**: Excellent - RÃ©ponse quasi-instantanÃ©e
- **200-500ms**: Bon - Acceptable pour mode standard
- **500-1000ms**: Moyen - Acceptable pour mode smart (raisonnement)
- **> 1000ms**: Lent - Peut nÃ©cessiter optimisation

### Tokens/sec
- **> 50 tok/s**: TrÃ¨s rapide - IdÃ©al pour mode standard
- **30-50 tok/s**: Rapide - Bon pour usage en temps rÃ©el
- **20-30 tok/s**: Moyen - Acceptable pour mode smart
- **< 20 tok/s**: Lent - Peut frustrer l'utilisateur

### Vision Support
Les modÃ¨les marquÃ©s âœ… peuvent traiter des screenshots. Essentiel pour:
- Analyse d'Ã©cran en temps rÃ©el
- Questions sur du contenu visuel
- Assistance sur des diagrammes/tableaux

---

## ğŸ› Debugging

### Erreur "No API key in database"
```bash
# VÃ©rifier que la clÃ© existe et est active
npx prisma studio
# â†’ Table AdminApiKey â†’ VÃ©rifier provider et isActive
```

### Erreur "Invalid or expired token"
```bash
# Re-gÃ©nÃ©rer une nouvelle clÃ© OpenAI
# â†’ https://platform.openai.com/api-keys
# â†’ Remplacer dans Prisma Studio
```

### Erreur "Model not found"
Le modÃ¨le n'est pas disponible dans votre compte OpenAI. VÃ©rifier:
- Votre plan OpenAI (certains modÃ¨les nÃ©cessitent un plan payant)
- L'orthographe exacte de l'ID du modÃ¨le
- La disponibilitÃ© du modÃ¨le (certains sont en beta limitÃ©e)

### Tests trÃ¨s lents
- VÃ©rifier votre connexion internet
- VÃ©rifier les limites de taux (rate limits) OpenAI
- Essayer Ã  un moment diffÃ©rent de la journÃ©e

---

## ğŸš€ DÃ©veloppement

### Ajouter un nouveau modÃ¨le Ã  tester

**1. Modifier `benchmark-openai.ts`:**
```typescript
const OPENAI_MODELS = {
  standard: [
    "gpt-5-mini",
    "nouveau-modele",  // Ajouter ici
  ],
  // ...
}
```

**2. ExÃ©cuter le benchmark:**
```bash
npm run benchmark:openai
```

### CrÃ©er un benchmark pour un autre provider

Copier `benchmark-openai.ts` et adapter:
- URL de l'API
- Format des requÃªtes
- Parsing des rÃ©ponses streaming

---

## ğŸ“ Notes

- Les tests utilisent le streaming pour mesurer le TTFB avec prÃ©cision
- Chaque test gÃ©nÃ¨re ~100 tokens pour des rÃ©sultats cohÃ©rents
- Les images de test sont des pixels 1x1 minimaux pour rÃ©duire la latence
- Les rÃ©sultats peuvent varier selon:
  - Charge du serveur OpenAI
  - Votre localisation gÃ©ographique
  - Votre connexion internet
  - L'heure de la journÃ©e

---

## ğŸ”— Liens utiles

- [OpenAI Models](https://platform.openai.com/docs/models)
- [OpenAI Rate Limits](https://platform.openai.com/docs/guides/rate-limits)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
